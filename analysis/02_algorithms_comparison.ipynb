{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms Comparison thorugh Monte Carlo Analysis\n",
    "In the first script, an analysis of the effect of the parasite terms (capacitance, $C_1$, and resistance, $R_0$) is performed using the Monte Carlo technique. This way, many simulations are performed to analyze the effect of the variations or uncertainties in the parasite terms over the theoretical estimation of viscosity through the step signal response. \n",
    "\n",
    "In this second script, the same approach is followed but with the aim of comparing the response of different algorithms to, first, the same parasite terms, and second, to different input signals.\n",
    "\n",
    "The content of this notebook is the following:\n",
    "- Assignation of values for all the elements of the circuits and their uncertainty ranges.\n",
    "- Definition of all the equations involved in the analysis.\n",
    "- Definition of estimation algorithms / load of estimation models.\n",
    "- Monte Carlo analysis routine for parasite terms.\n",
    "- Monte Carlo analysis routine for input signals.\n",
    "- Results analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pywt\n",
    "\n",
    "from scipy import signal\n",
    "from scipy.integrate import solve_ivp\n",
    "from scipy.stats import norm as norm_dist\n",
    "\n",
    "import pysindy as psdy\n",
    "\n",
    "from nfoursid.nfoursid import NFourSID as nfsid\n",
    "\n",
    "from sysidentpy.model_structure_selection import FROLS as sipFROLS\n",
    "from sysidentpy.basis_function._basis_function import Polynomial as sipPoly\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'ignore', 'over': 'warn', 'under': 'ignore', 'invalid': 'ignore'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.seterr(divide='ignore', invalid='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Elements of the circuit\n",
    "The simulated circuit is showing here:\n",
    "\n",
    "*Insert a diagram of the circuit*\n",
    "\n",
    "Each dictionary holds the required values to define the associated element of the circuit. Within the dictionary there is a list called `\"e_sources\"`, or error sources. This list will contain all the parameters to be randomly modified in the Monte Carlo analysis. To do so, the parameter must have an associated parameter `_e`, which defined the absolute error associated to the parameter.\n",
    "\n",
    "For example, if the diameter, `D`, of the first resistance, `R0`, must be analyzed, it must have an associated parameter `D_e`, defining the absolute uncertainty of that parameter. Also, `D` must be then included in the list `e_sources` of `R0`.\n",
    "\n",
    "**Note**: It is important to respect the nomenclature in the dictionary of parameters. If it is a resistive element, it must start by `R`. If it is capacitive, `C`. After the identificative number, use a low bar, `_`, for the second part of the name (e.g. `R0_params`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input resistance\n",
    "elements = {\n",
    "    \"R0_params\": {\n",
    "        \"D\": 500e-6,\n",
    "        \"L\": 125e-2, # 25e-2\n",
    "        \"e_sources\": [],\n",
    "        \"e\": {\n",
    "            \"D_e\": 50e-6,\n",
    "            \"L_e\": 1e-3\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # First RC Branch\n",
    "    \"R1_params\": {\n",
    "        \"D\": 150e-6,\n",
    "        \"L\": 10e-2,\n",
    "        \"e_sources\": [],\n",
    "        \"e\": {\n",
    "            \"D_e\": 15e-6,\n",
    "            \"L_e\": 1e-3\n",
    "        }\n",
    "    },\n",
    "    \"C1_params\": {\n",
    "        \"D\": 2e-3,\n",
    "        \"L\": 1.0e-2,\n",
    "        \"E\": 10e6,\n",
    "        \"t\": 0.75e-3,\n",
    "        \"beta\": 2.5e9,\n",
    "        \"e_sources\": [\"L\"],\n",
    "        \"e\": {\n",
    "            \"D_e\": 0.0,\n",
    "            \"L_e\": 0.5e-2\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # Second RC branch\n",
    "    \"R2_params\": {\n",
    "        \"D\": 150e-6,\n",
    "        \"L\": 10e-2,\n",
    "        \"e_sources\": [],\n",
    "        \"e\": {\n",
    "            \"D_e\": 15e-6,\n",
    "            \"L_e\": 1e-3\n",
    "        }\n",
    "    },\n",
    "    \"C2_params\": {\n",
    "        \"D\": 2e-3,\n",
    "        \"L\": 10e-2,\n",
    "        \"E\": 10e6,\n",
    "        \"t\": 0.75e-3,\n",
    "        \"beta\": 2.5e9,\n",
    "        \"e_sources\": [],\n",
    "        \"e\": {\n",
    "            \"D_e\": 5e-4,\n",
    "            \"L_e\": 1e-3\n",
    "        }\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'R0_params': {'D': (0.0005, 0.0005), 'L': (1.25, 1.25)}, 'R1_params': {'D': (0.00015, 0.00015), 'L': (0.1, 0.1)}, 'C1_params': {'E': (10000000.0, 10000000.0), 'D': (0.002, 0.002), 'L': (0.005, 0.015), 'beta': (2500000000.0, 2500000000.0), 't': (0.00075, 0.00075)}, 'R2_params': {'D': (0.00015, 0.00015), 'L': (0.1, 0.1)}, 'C2_params': {'E': (10000000.0, 10000000.0), 'D': (0.002, 0.002), 'L': (0.1, 0.1), 'beta': (2500000000.0, 2500000000.0), 't': (0.00075, 0.00075)}}\n"
     ]
    }
   ],
   "source": [
    "# Use the above dictionaries to define the ranges\n",
    "ranges_dict = {}\n",
    "for ky, element in elements.items():\n",
    "    ranges_dict[ky] = {}\n",
    "    for param in set(element.keys())-set([\"e_sources\", \"e\"]):\n",
    "        if param in element[\"e_sources\"]:\n",
    "            ranges_dict[ky][param] = (element[param] - element[\"e\"][param+\"_e\"],\n",
    "                                      element[param] + element[\"e\"][param+\"_e\"])\n",
    "        else:\n",
    "            ranges_dict[ky][param] = (element[param], element[param])\n",
    "\n",
    "print(ranges_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "\n",
    "class constant_signal:\n",
    "    def __init__(self) -> None:\n",
    "        self.__name__ = \"constant_signal\"\n",
    "\n",
    "    def __call__(self, t, A=1.0, k=1.0):\n",
    "        return A\n",
    "\n",
    "class sinusoidal_signal:\n",
    "    def __init__(self) -> None:\n",
    "        self.__name__ = \"sinusoidal_signal\"\n",
    "        \n",
    "    def __call__(self, t, A=1.0, k=1.0):\n",
    "        return A*np.sin(k*t)\n",
    "\n",
    "class triangular_signal:\n",
    "    def __init__(self) -> None:\n",
    "        self.__name__ = \"triangular_signal\"\n",
    "        \n",
    "    def __call__(self, t, A=1.0, k=1.0):\n",
    "        return A*(signal.sawtooth(2*np.pi*k*t, 0.5)+1.0) / 2\n",
    "\n",
    "class db5_signal:\n",
    "    def __init__(self) -> None:\n",
    "        self.__name__ = \"db5_signal\"\n",
    "        self.wavelet = pywt.Wavelet(\"db5\")\n",
    "        phi, psi, x = self.wavelet.wavefun(level=8)\n",
    "        # TODO remove the first second to t_sim seconds\n",
    "        # TODO interpolation function\n",
    "\n",
    "    def __call__(self, t, A=1.0, k=1.0):\n",
    "        # TODO call the interpolation function\n",
    "        return A*psi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Physical Equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class calc_water_viscosity:\n",
    "    \"\"\"\n",
    "    Calculates the viscosity at some temperature, in Kelvin.\n",
    "\n",
    "    This is a functor, so it must first be declared (changing the parameters if\n",
    "    needed), and, after that, it can be called as any other function.\n",
    "    \"\"\"\n",
    "    def __init__(self, A=2.414e-5, B=247.8, C=140):\n",
    "        self.A = A\n",
    "        self.B = B\n",
    "        self.C = C\n",
    "    def __call__(self, temp_K):\n",
    "        return self.A * 10 ** (self.B / (temp_K - self.C))\n",
    "\n",
    "def calc_cil_resistance(D, L, visc):\n",
    "    \"\"\"\n",
    "    Calculates the hydraulic resistance for a cylindrical tube,\n",
    "    for a given viscosity.\n",
    "    \"\"\"\n",
    "    return 8*visc*L / (np.pi*((D/2)**4))\n",
    "\n",
    "def calc_cil_capacitance(D, L, beta, E, t):\n",
    "    \"\"\"\n",
    "    Calculates the theoretical capacitance of a cylindrical tube.\n",
    "    \"\"\"\n",
    "    # Beta := Bulk Modulus of Water\n",
    "    V0 = np.pi*(D/2)**2 * L\n",
    "    return (V0 / beta)*( 1 + ((beta*D)/(E*t)) )\n",
    "\n",
    "def circuit_dyn_eqs(t, dP, args): # R0, R1, R2, C1, C2, Pin\n",
    "    \"\"\"\n",
    "    Calcualtes the differential values of pressure drop over the\n",
    "    two RC branches of the circuit.\n",
    "    \"\"\"\n",
    "    P1, P2 = dP # Integration of previous dP1, dP2\n",
    "    R0 = args[\"R0\"]\n",
    "    R1 = args[\"R1\"]\n",
    "    R2 = args[\"R2\"]\n",
    "    C1 = args[\"C1\"]\n",
    "    C2 = args[\"C2\"] \n",
    "    # Pin = args[\"Pin\"]\n",
    "    Pin = args[\"Pin\"](t)\n",
    "\n",
    "    dP1 = (Pin - P1)/(R0 * C1) - P1 / (R1 * C1)\n",
    "    dP2 = (P1 - P2)/(R2 * C2)\n",
    "    return [dP1, dP2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Estimation Algorithms\n",
    "There are six compared viscosity estimation algorithms: two based on classical techniques (N4SID and SINDy), and four based on deep learning techniques. Within the deep learning models, one is based on Convolutional Neural Networks (CNN), and the other is based on Long-Short Term Memory (LSTM) networks. The two remaining deep learning models are the quantized versions of the CNN and LSTM based models. This is done in this way such that classical techniques, which are easily implemented as embedded software, can be benchmarked under the conditions that the deep learning techniques would have as embedded software. \n",
    "\n",
    "- One observed limitation for SINDy is its dependence on the data points. If it is small, the quality of the discovered models (and the coefficients) can be very poor when compared with other techniques.\n",
    "\n",
    "### 3.1 Classical-ish Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "\n",
    "def estimate_visc(t, P2_t, R2, C2, visc):\n",
    "    \"\"\"\n",
    "    Estimates the viscosity from an step response of the target \n",
    "    microfluidic RC circuit. It assumes that there is not noise.\n",
    "\n",
    "    The viscosity is asked as argument because R2 is assumed to \n",
    "    contain the viscosity. \n",
    "    \"\"\"\n",
    "    P_ss = P2_t[-1]\n",
    "    if np.abs(P2_t[-1]-P2_t[-2]) > np.abs(0.02*P2_t[-1]):\n",
    "        print(\"W: steady state value was not steady calculating visc.\")\n",
    "    P_tau = 0.632 * P_ss\n",
    "    # Get closest time, t\n",
    "    tau = t[ np.argmin(np.abs(np.subtract(P2_t, P_tau))) ]\n",
    "\n",
    "    Rg = R2 / visc\n",
    "    return tau / (Rg*C2)\n",
    "\n",
    "class estimate_visc_sindy:\n",
    "    def __init__(self) -> None:\n",
    "        self.model = psdy.SINDy()\n",
    "\n",
    "    def __call__(self, t, P1_t, P2_t):\n",
    "        self.model.fit(P2_t, u=P1_t, t=t[1]-t[0])\n",
    "        # Get tau as the mean estimated from both variables\n",
    "        # Model: dP2/dt = tau_a*P1 - tau_b*P2 -> tau = (tau_a+tau_b)/2\n",
    "        return 1/np.mean(np.abs(self.model.coefficients()[0][1:3]))\n",
    "\n",
    "class estimate_visc_n4sid:\n",
    "    def __init__(self) -> None:\n",
    "        self.ident = nfsid(\n",
    "            pd.DataFrame(), \n",
    "            output_columns=[]\n",
    "        )\n",
    "        self.order = 1\n",
    "\n",
    "    def __call__(self, t, P1_t, P2_t):\n",
    "        self.ident.u_array = np.reshape(P1_t, [np.shape(P1_t)[0], 1])\n",
    "        self.ident.u_dim = np.shape(self.ident.u_array)[1]\n",
    "        self.ident.y_array = np.reshape(P2_t, [np.shape(P2_t)[0], 1])\n",
    "        self.ident.y_dim = np.shape(self.ident.y_array)[1]\n",
    "\n",
    "        self.ident.subspace_identification()\n",
    "\n",
    "        ORDER_OF_MODEL_TO_FIT = 1\n",
    "        identified_sys, cov_matrix = \\\n",
    "            self.ident.system_identification( rank=self.order )\n",
    "        \n",
    "        # From discrete to continuous\n",
    "        incT = t[1]-t[0]\n",
    "        tau1 = incT / (1-identified_sys.a[0][0])\n",
    "        tau2 = incT / identified_sys.d[0][0]\n",
    "        return tau1 # np.mean(np.abs([tau1, tau2]))\n",
    "\n",
    "class estimate_visc_forl:\n",
    "    def __init__(self) -> None:\n",
    "        self.model = sipFROLS(\n",
    "            order_selection=True,\n",
    "            n_info_values=10,\n",
    "            extended_least_squares=False,\n",
    "            ylag=1,\n",
    "            xlag=1,\n",
    "            info_criteria='aic',\n",
    "            estimator=\"least_squares\",\n",
    "            basis_function=sipPoly(degree=1),\n",
    "        )\n",
    "\n",
    "    def __call__(self, t, P1_t, P2_t):\n",
    "        x = np.reshape(P1_t, [np.shape(P1_t)[0], 1])\n",
    "        y = np.reshape(P2_t, [np.shape(P2_t)[0], 1])\n",
    "\n",
    "        self.model.fit(X=x, y=y)\n",
    "\n",
    "        # The ARMAX model is discrete, it's necessary to recover\n",
    "        # the time constant, tau, from it.\n",
    "        incT = t[1]-t[0]\n",
    "        tau1 = incT / (1-self.model.theta[0])\n",
    "        tau2 = incT / self.model.theta[2]\n",
    "        # print(model.theta)\n",
    "        # print(tau1, tau2)\n",
    "        return np.mean(np.abs([tau1, tau2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 DL Estimation Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "\n",
    "class estimate_visc_ann:\n",
    "    def __init__(self, model_path, model_cfg) -> None:\n",
    "        # Load the model\n",
    "        self.model = tf.keras.layers.TFSMLayer(model_path, \n",
    "                                               call_endpoint=\"serving_default\")\n",
    "        # Load the configuration of the model\n",
    "        with open(model_cfg) as cfg_file:\n",
    "            self.cfg = yaml.safe_load(cfg_file)\n",
    "    \n",
    "    def _format_in(self, P1_t, P2_t):\n",
    "        X1 = (np.array(P1_t) - self.cfg[\"in\"][\"min\"][0]) / self.cfg[\"in\"][\"range\"][0]\n",
    "        X2 = (np.array(P2_t) - self.cfg[\"in\"][\"min\"][1]) / self.cfg[\"in\"][\"range\"][1]\n",
    "        X = [X1, X2]\n",
    "        return np.transpose(X).reshape(1, -1, np.shape(X)[0])\n",
    "\n",
    "    def _undo_norm(self, y):\n",
    "        return self.cfg[\"out\"][\"range\"][0] * y + self.cfg[\"out\"][\"min\"][0]\n",
    "\n",
    "    def __call__(self, t, P1_t, P2_t):\n",
    "        \"\"\"\n",
    "        The model is trained to estimate the param alpha = (incT) / (Rg*C*visc)\n",
    "\n",
    "        Thus, it returns the parameter beta = incT / alpha, which is the param\n",
    "        independent of sampling time, from which the viscosity can be calculated\n",
    "        using the values of the circuit.\n",
    "        \"\"\"\n",
    "        # Format the input\n",
    "        X = self._format_in(P1_t, P2_t)\n",
    "        # Forward the model\n",
    "        y = self.model(X)[\"output_0\"]\n",
    "        alpha = self._undo_norm( tf.squeeze(y).numpy() )\n",
    "        # Get the right output format\n",
    "        incT = t[1]-t[0]\n",
    "        return 10*incT / alpha\n",
    "\n",
    "\n",
    "class estimate_visc_qann:\n",
    "    def __init__(self, model_path, model_cfg) -> None:\n",
    "        \"\"\"\n",
    "        For now, only automatically quantized inputs/outputs are here allowed.\n",
    "        \"\"\"\n",
    "        # Load the model\n",
    "        self.interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "        self.interpreter.allocate_tensors()\n",
    "        self.input_details = self.interpreter.get_input_details()[0]\n",
    "        print(\"Input: {}\".format(self.input_details[\"dtype\"]))\n",
    "        self.output_details = self.interpreter.get_output_details()[0]\n",
    "        print(\"Output: {}\".format(self.output_details[\"dtype\"]))\n",
    "        self.output_buffer = 0.0\n",
    "        if \"cnn\" in model_path:\n",
    "            self.ann_type = \"cnn\"\n",
    "        else: \n",
    "            self.ann_type = \"lstm\"\n",
    "\n",
    "        # Load the configuration of the model\n",
    "        with open(model_cfg) as cfg_file:\n",
    "            self.cfg = yaml.safe_load(cfg_file)\n",
    "    \n",
    "    def _format_in(self, P1_t, P2_t):\n",
    "        X1 = (np.array(P1_t) - self.cfg[\"in\"][\"min\"][0]) / self.cfg[\"in\"][\"range\"][0]\n",
    "        X2 = (np.array(P2_t) - self.cfg[\"in\"][\"min\"][1]) / self.cfg[\"in\"][\"range\"][1]\n",
    "        X = [X1, X2]\n",
    "        X = np.float32( np.transpose(X).reshape(1, -1, np.shape(X)[0]) )\n",
    "        if self.ann_type == \"cnn\":\n",
    "            return np.expand_dims(X, axis=-1)\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "    def _undo_norm(self, y):\n",
    "        return self.cfg[\"out\"][\"range\"][0] * y + self.cfg[\"out\"][\"min\"][0]\n",
    "\n",
    "    def __call__(self, t, P1_t, P2_t):\n",
    "        \"\"\"\n",
    "        The model is trained to estimate the param alpha = (incT) / (Rg*C*visc)\n",
    "\n",
    "        Thus, it returns the parameter beta = incT / alpha, which is the param\n",
    "        independent of sampling time, from which the viscosity can be calculated\n",
    "        using the values of the circuit.\n",
    "        \"\"\"\n",
    "        # Format the input\n",
    "        X = self._format_in(P1_t, P2_t)\n",
    "        # Forward the model\n",
    "        self.interpreter.set_tensor(self.input_details[\"index\"], X)\n",
    "        self.interpreter.invoke()\n",
    "        self.output_buffer = self.interpreter.get_tensor(self.output_details[\"index\"])\n",
    "        # Get the right output format\n",
    "        alpha = self._undo_norm( tf.squeeze(self.output_buffer).numpy() )\n",
    "        incT = t[1]-t[0]\n",
    "        return 10*incT / alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Juan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sysidentpy\\utils\\deprecation.py:40: FutureWarning: Passing a string to define the estimator will rise an error in v0.4.0. \n",
      " You'll have to use FROLS(estimator=LeastSquares()) instead. \n",
      " The only change is that you'll have to define the estimator first instead of passing a string like 'least_squares'. \n",
      " This change will make easier to implement new estimators and it'll improve code readability.\n",
      "  warnings.warn(message, FutureWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <class 'numpy.float32'>\n",
      "Output: <class 'numpy.float32'>\n",
      "Input: <class 'numpy.float32'>\n",
      "Output: <class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "lstm_model_path = \"..\\processing\\models\\lstm_2024_08_28_16_48.model\"\n",
    "lstm_model_cfg = \"..\\processing\\data\\dataset04_alpha_500samples\\model_cfg.yaml\"\n",
    "\n",
    "cnn_model_path = \"..\\processing\\models\\cnn_2024_08_28_12_33.model\"\n",
    "cnn_model_cfg = \"..\\processing\\data\\dataset04_alpha_500samples\\model_cfg.yaml\"\n",
    "\n",
    "qlstm_model_path = \"..\\processing\\models\\quantized\\lstm_2024_08_28_16_48\\lstm_2024_08_28_16_48.tflite\"\n",
    "qlstm_model_cfg = \"..\\processing\\data\\dataset04_alpha_500samples\\model_cfg.yaml\"\n",
    "\n",
    "qcnn_model_path = \"..\\processing\\models\\quantized\\cnn_2024_08_28_12_33\\cnn_2024_08_28_12_33.tflite\"\n",
    "qcnn_model_cfg = \"..\\processing\\data\\dataset04_alpha_500samples\\model_cfg.yaml\"\n",
    "\n",
    "\n",
    "# Encapsulate all algorithms inside a dictionary\n",
    "alg_dict = {\n",
    "    \"sindy\": estimate_visc_sindy(),\n",
    "    \"n4sid\": estimate_visc_n4sid(),\n",
    "    \"forl\": estimate_visc_forl(),\n",
    "    \"lstm\": estimate_visc_ann(lstm_model_path, lstm_model_cfg),\n",
    "    \"cnn\": estimate_visc_ann(cnn_model_path, cnn_model_cfg),\n",
    "    \"qlstm\": estimate_visc_qann(qlstm_model_path, qlstm_model_cfg),\n",
    "    \"qcnn\": estimate_visc_qann(qcnn_model_path, qcnn_model_cfg)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Monte Carlo Analysis - Parasite Terms\n",
    "For each of the element of the circuit, there are some defined ranges of values that the element can take. The objective of this analysis is to study how much will affect each of the variations to the output estimation of viscosity.\n",
    "\n",
    "The analysis is performed by running a large number of simulations (proportional to the complexity of the system and the number of uncertain variables), propagating each variation to an objective value. For example, if the uncertainty source is one dimension of a resistance, the resistance will be calculated for each simulation with a dimension randomly chosen within the defined range. For each simulation, the viscosity will be calculated. The variation at viscosity is then compared with the variation of the input parameter, producing a sensibility estimation between both of them.\n",
    "\n",
    "In this case, the objective parameter is the parasite capacitance. Each of the estimation algorithms is tested with varying paratise terms such that their sensibility to erroneous calibration and parasite effects can be determined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:09<00:00, 10.07it/s]\n"
     ]
    }
   ],
   "source": [
    "Pin = 20e4 # Pressure input in Pa: 20e4 Pa = 2000 mbar\n",
    "\n",
    "t_sim = 5 # Must be large enough to reach steady state\n",
    "t_points = 500 # This affects to the accuracy estimating tau\n",
    "N = 100 # Number of simulations\n",
    "\n",
    "temp_C = 28.65 # In Celsius\n",
    "temp_K = temp_C + 273.15\n",
    "\n",
    "\n",
    "visc_calc = calc_water_viscosity()\n",
    "visc = visc_calc(temp_K)\n",
    "\n",
    "results = {}\n",
    "for ky in ranges_dict.keys():\n",
    "    results[ky.split(\"_\")[0]] = []\n",
    "for alg_name in alg_dict.keys():\n",
    "    results[alg_name+\"_est_visc\"] = []\n",
    "    results[alg_name+\"_tau2\"] = []\n",
    "\n",
    "for n in tqdm(range(N)): # For progress bar\n",
    "    # Get the values of the parameters\n",
    "    # sim_params = { \"Pin\": Pin }\n",
    "    sim_params = { \"Pin\": constant_signal() }\n",
    "\n",
    "    for ky, element_ranges in ranges_dict.items():\n",
    "        # Extract the random values for the parameters\n",
    "        args = {}\n",
    "        for param, param_ranges in element_ranges.items():\n",
    "            args[param] = np.max([0.0, np.random.uniform(*param_ranges)])\n",
    "        # Resistance\n",
    "        if ky[0] == \"R\":\n",
    "            sim_params[ky.split(\"_\")[0]] = calc_cil_resistance(**args, visc=visc)\n",
    "        # Capacitance\n",
    "        elif ky[0] == \"C\":\n",
    "            sim_params[ky.split(\"_\")[0]] = calc_cil_capacitance(**args)\n",
    "        else: \n",
    "            print(\"Error: element {} not recognized\".format(ky))\n",
    "            exit()\n",
    "        \n",
    "    # Perform the simulation\n",
    "    sol = solve_ivp(circuit_dyn_eqs, [0, t_sim], [0, 0], args=(sim_params,), \n",
    "                    dense_output=True)\n",
    "    \n",
    "    # Save the results\n",
    "    t = np.linspace(0, t_sim, t_points)\n",
    "    P1_t = sol.sol(t)[0]\n",
    "    P2_t = sol.sol(t)[1]\n",
    "\n",
    "    # If you want to print some curves, don't make N very large\n",
    "    # plt.plot(t, P2_t)\n",
    "    # plt.plot(t, P1_t)\n",
    "    # plt.show()\n",
    "\n",
    "    for alg_name in alg_dict.keys():\n",
    "        # Estimate viscosity\n",
    "        R2g = sim_params[\"R2\"] / visc\n",
    "        tau2 = alg_dict[alg_name](t, P1_t, P2_t)\n",
    "        est_visc = tau2 / (R2g*sim_params[\"C2\"])\n",
    "        # Save the results\n",
    "        results[alg_name+\"_tau2\"].append(tau2)\n",
    "        results[alg_name+\"_est_visc\"].append(est_visc)\n",
    "\n",
    "    # Update the results dict\n",
    "    for ky in ranges_dict.keys():\n",
    "        results[ky.split(\"_\")[0]].append( sim_params[ky.split(\"_\")[0]] )\n",
    "\n",
    "res_df = pd.DataFrame.from_dict(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Algorithms Performance Analysis by Input Signal\n",
    "\n",
    "In this section, the estimation algorithms are tested with different input: step, sinusoidal, triangular and daubechies (heartbeat) signals, with and without injected noise. The objective is to test their performance in many different situations so a benchmark can be produced to understand the advantages of each one depending on the situation.\n",
    "\n",
    "In this analysis, the **viscosity is randomly changed** within a defined range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_conditions = [\n",
    "    {\"sig\": constant_signal(), \"noise\": 0.0},\n",
    "    {\"sig\": constant_signal(), \"noise\": 0.04},\n",
    "    {\"sig\": sinusoidal_signal(), \"noise\": 0.0},\n",
    "    {\"sig\": sinusoidal_signal(), \"noise\": 0.04},\n",
    "    {\"sig\": triangular_signal(), \"noise\": 0.0},\n",
    "    {\"sig\": triangular_signal(), \"noise\": 0.04}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating with conditions set 1 / 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 11.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating with conditions set 2 / 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 12.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating with conditions set 3 / 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 12.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating with conditions set 4 / 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 11.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating with conditions set 5 / 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:17<00:00,  5.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating with conditions set 6 / 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:17<00:00,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "t_sim = 5 # Must be large enough to reach steady state\n",
    "t_points = 500 # This affects to the accuracy estimating tau\n",
    "N = 100 # Number of simulations\n",
    "\n",
    "visc_range = (8.1e-4, 8.9e-4)\n",
    "\n",
    "res_sig_dict = {\n",
    "    \"visc\": [],\n",
    "    \"tau\": [],\n",
    "    \"est_visc\": [],\n",
    "    \"est_acc\": [],\n",
    "    \"algorithm\": [],\n",
    "    \"signal\": [],\n",
    "    \"noise\": [],\n",
    "    \"time\": []\n",
    "}\n",
    "\n",
    "for sim_i, sim_cond in enumerate(sim_conditions):\n",
    "    print(\"Simulating with conditions set {} / {}\".format(\n",
    "        sim_i+1, len(sim_conditions)))\n",
    "    for n in tqdm(range(N)): # For progress bar\n",
    "        # Get the values of the parameters\n",
    "        sim_params = { \"Pin\": sim_cond[\"sig\"] }\n",
    "        # Get a random value of viscosity within range\n",
    "        visc = np.max([0.0, np.random.uniform(*visc_range)])\n",
    "\n",
    "        for ky, element_ranges in ranges_dict.items():\n",
    "            # Extract the random values for the parameters\n",
    "            args = {}\n",
    "            for param, param_ranges in element_ranges.items():\n",
    "                # We just take the bigger element. No random\n",
    "                args[param] = np.max([0.0, param_ranges[1]])\n",
    "            # Resistance\n",
    "            if ky[0] == \"R\":\n",
    "                sim_params[ky.split(\"_\")[0]] = calc_cil_resistance(**args, visc=visc)\n",
    "            # Capacitance\n",
    "            elif ky[0] == \"C\":\n",
    "                sim_params[ky.split(\"_\")[0]] = calc_cil_capacitance(**args)\n",
    "            else: \n",
    "                print(\"Error: element {} not recognized\".format(ky))\n",
    "                exit()\n",
    "            \n",
    "        # Perform the simulation\n",
    "        sol = solve_ivp(circuit_dyn_eqs, [0, t_sim], [0, 0], args=(sim_params,), \n",
    "                        dense_output=True)\n",
    "        \n",
    "        # Save the results\n",
    "        t = np.linspace(0, t_sim, t_points)\n",
    "        P1_t = sol.sol(t)[0]\n",
    "        P2_t = sol.sol(t)[1]\n",
    "\n",
    "        # Add measurement noise\n",
    "        if sim_cond[\"noise\"] > 0.0:\n",
    "            P1_t += np.random.normal(0.0, sim_cond[\"noise\"], np.shape(P1_t))\n",
    "            P2_t += np.random.normal(0.0, sim_cond[\"noise\"], np.shape(P2_t))\n",
    "\n",
    "        # If you want to print some curves, don't make N very large\n",
    "        # plt.plot(t, P2_t)\n",
    "        # plt.plot(t, P1_t)\n",
    "        # plt.show()\n",
    "\n",
    "        for alg_name in alg_dict.keys():\n",
    "            # Estimate viscosity\n",
    "            start = time.time() # Alg. Execution Performance - Start\n",
    "\n",
    "            R2g = sim_params[\"R2\"] / visc\n",
    "            tau2 = alg_dict[alg_name](t, P1_t, P2_t)\n",
    "            est_visc = tau2 / (R2g*sim_params[\"C2\"])\n",
    "\n",
    "            end = time.time() #  Alg. Execution Performance - Finish\n",
    "\n",
    "            # Save the results\n",
    "            res_sig_dict[\"visc\"].append( visc )\n",
    "            res_sig_dict[\"algorithm\"].append( alg_name )\n",
    "            res_sig_dict[\"est_visc\"].append( est_visc )\n",
    "            res_sig_dict[\"est_acc\"].append( np.abs((visc - est_visc) / visc) * 100 )\n",
    "            res_sig_dict[\"tau\"].append( tau2 )\n",
    "            res_sig_dict[\"signal\"].append( sim_cond[\"sig\"].__name__ )\n",
    "            res_sig_dict[\"noise\"].append( sim_cond[\"noise\"] )\n",
    "            res_sig_dict[\"time\"].append( end - start )\n",
    "\n",
    "print(\"Done.\")\n",
    "res_sig_df = pd.DataFrame.from_dict(res_sig_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Validation with Experimental Data\n",
    "In this section, the algorithms process experimental signals from the built prototype to test their accuracy with real data. The experimental data is composed of pressure signals gathered in experiments using the prototype with different input pressure patterns (step, sinusoidal, etc.) and fluids (water, IPA, ethanol 70%, etc.). Each signal has a reference viscosity value obtained from an accurate viscometer.\n",
    "\n",
    "For the values of the elements of the experimental setup, it is also allowed to set a range for each dimension such that any uncertainty (e.g. from manufacturing process) can be inserted in the analysis like for the Monte Carlo analysis.\n",
    "\n",
    "This validation dataset is used to benchmark each method's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Juan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pysindy\\optimizers\\stlsq.py:191: UserWarning: Sparsity parameter is too big (0.1) and eliminated all coefficients\n",
      "  warnings.warn(\n",
      "c:\\Users\\Juan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pysindy\\optimizers\\stlsq.py:191: UserWarning: Sparsity parameter is too big (0.1) and eliminated all coefficients\n",
      "  warnings.warn(\n",
      "c:\\Users\\Juan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pysindy\\optimizers\\stlsq.py:191: UserWarning: Sparsity parameter is too big (0.1) and eliminated all coefficients\n",
      "  warnings.warn(\n",
      "c:\\Users\\Juan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pysindy\\optimizers\\stlsq.py:191: UserWarning: Sparsity parameter is too big (0.1) and eliminated all coefficients\n",
      "  warnings.warn(\n",
      "c:\\Users\\Juan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pysindy\\optimizers\\stlsq.py:191: UserWarning: Sparsity parameter is too big (0.1) and eliminated all coefficients\n",
      "  warnings.warn(\n",
      "c:\\Users\\Juan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pysindy\\optimizers\\stlsq.py:191: UserWarning: Sparsity parameter is too big (0.1) and eliminated all coefficients\n",
      "  warnings.warn(\n",
      "c:\\Users\\Juan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pysindy\\optimizers\\stlsq.py:191: UserWarning: Sparsity parameter is too big (0.1) and eliminated all coefficients\n",
      "  warnings.warn(\n",
      "c:\\Users\\Juan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pysindy\\optimizers\\stlsq.py:191: UserWarning: Sparsity parameter is too big (0.1) and eliminated all coefficients\n",
      "  warnings.warn(\n",
      "c:\\Users\\Juan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pysindy\\optimizers\\stlsq.py:191: UserWarning: Sparsity parameter is too big (0.1) and eliminated all coefficients\n",
      "  warnings.warn(\n",
      "c:\\Users\\Juan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pysindy\\optimizers\\stlsq.py:191: UserWarning: Sparsity parameter is too big (0.1) and eliminated all coefficients\n",
      "  warnings.warn(\n",
      "c:\\Users\\Juan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pysindy\\optimizers\\stlsq.py:191: UserWarning: Sparsity parameter is too big (0.1) and eliminated all coefficients\n",
      "  warnings.warn(\n",
      "c:\\Users\\Juan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pysindy\\optimizers\\stlsq.py:191: UserWarning: Sparsity parameter is too big (0.1) and eliminated all coefficients\n",
      "  warnings.warn(\n",
      "c:\\Users\\Juan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pysindy\\optimizers\\stlsq.py:191: UserWarning: Sparsity parameter is too big (0.1) and eliminated all coefficients\n",
      "  warnings.warn(\n",
      "c:\\Users\\Juan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pysindy\\optimizers\\stlsq.py:191: UserWarning: Sparsity parameter is too big (0.1) and eliminated all coefficients\n",
      "  warnings.warn(\n",
      "c:\\Users\\Juan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pysindy\\optimizers\\stlsq.py:191: UserWarning: Sparsity parameter is too big (0.1) and eliminated all coefficients\n",
      "  warnings.warn(\n",
      "c:\\Users\\Juan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pysindy\\optimizers\\stlsq.py:191: UserWarning: Sparsity parameter is too big (0.1) and eliminated all coefficients\n",
      "  warnings.warn(\n",
      "c:\\Users\\Juan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pysindy\\optimizers\\stlsq.py:191: UserWarning: Sparsity parameter is too big (0.1) and eliminated all coefficients\n",
      "  warnings.warn(\n",
      "c:\\Users\\Juan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pysindy\\optimizers\\stlsq.py:191: UserWarning: Sparsity parameter is too big (0.1) and eliminated all coefficients\n",
      "  warnings.warn(\n",
      "c:\\Users\\Juan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pysindy\\optimizers\\stlsq.py:191: UserWarning: Sparsity parameter is too big (0.1) and eliminated all coefficients\n",
      "  warnings.warn(\n",
      "c:\\Users\\Juan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pysindy\\optimizers\\stlsq.py:191: UserWarning: Sparsity parameter is too big (0.1) and eliminated all coefficients\n",
      "  warnings.warn(\n",
      "c:\\Users\\Juan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pysindy\\optimizers\\stlsq.py:191: UserWarning: Sparsity parameter is too big (0.1) and eliminated all coefficients\n",
      "  warnings.warn(\n",
      "c:\\Users\\Juan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pysindy\\optimizers\\stlsq.py:191: UserWarning: Sparsity parameter is too big (0.1) and eliminated all coefficients\n",
      "  warnings.warn(\n",
      "c:\\Users\\Juan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pysindy\\optimizers\\stlsq.py:191: UserWarning: Sparsity parameter is too big (0.1) and eliminated all coefficients\n",
      "  warnings.warn(\n",
      "c:\\Users\\Juan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pysindy\\optimizers\\stlsq.py:191: UserWarning: Sparsity parameter is too big (0.1) and eliminated all coefficients\n",
      "  warnings.warn(\n",
      "c:\\Users\\Juan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pysindy\\optimizers\\stlsq.py:191: UserWarning: Sparsity parameter is too big (0.1) and eliminated all coefficients\n",
      "  warnings.warn(\n",
      "c:\\Users\\Juan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pysindy\\optimizers\\stlsq.py:191: UserWarning: Sparsity parameter is too big (0.1) and eliminated all coefficients\n",
      "  warnings.warn(\n",
      "c:\\Users\\Juan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pysindy\\optimizers\\stlsq.py:191: UserWarning: Sparsity parameter is too big (0.1) and eliminated all coefficients\n",
      "  warnings.warn(\n",
      "c:\\Users\\Juan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pysindy\\optimizers\\stlsq.py:191: UserWarning: Sparsity parameter is too big (0.1) and eliminated all coefficients\n",
      "  warnings.warn(\n",
      "c:\\Users\\Juan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pysindy\\optimizers\\stlsq.py:191: UserWarning: Sparsity parameter is too big (0.1) and eliminated all coefficients\n",
      "  warnings.warn(\n",
      "c:\\Users\\Juan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pysindy\\optimizers\\stlsq.py:191: UserWarning: Sparsity parameter is too big (0.1) and eliminated all coefficients\n",
      "  warnings.warn(\n",
      "c:\\Users\\Juan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pysindy\\optimizers\\stlsq.py:191: UserWarning: Sparsity parameter is too big (0.1) and eliminated all coefficients\n",
      "  warnings.warn(\n",
      "c:\\Users\\Juan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pysindy\\optimizers\\stlsq.py:191: UserWarning: Sparsity parameter is too big (0.1) and eliminated all coefficients\n",
      "  warnings.warn(\n",
      "c:\\Users\\Juan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pysindy\\optimizers\\stlsq.py:191: UserWarning: Sparsity parameter is too big (0.1) and eliminated all coefficients\n",
      "  warnings.warn(\n",
      "c:\\Users\\Juan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pysindy\\optimizers\\stlsq.py:191: UserWarning: Sparsity parameter is too big (0.1) and eliminated all coefficients\n",
      "  warnings.warn(\n",
      "c:\\Users\\Juan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pysindy\\optimizers\\stlsq.py:191: UserWarning: Sparsity parameter is too big (0.1) and eliminated all coefficients\n",
      "  warnings.warn(\n",
      "c:\\Users\\Juan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pysindy\\optimizers\\stlsq.py:191: UserWarning: Sparsity parameter is too big (0.1) and eliminated all coefficients\n",
      "  warnings.warn(\n",
      "c:\\Users\\Juan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pysindy\\optimizers\\stlsq.py:191: UserWarning: Sparsity parameter is too big (0.1) and eliminated all coefficients\n",
      "  warnings.warn(\n",
      "c:\\Users\\Juan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pysindy\\optimizers\\stlsq.py:191: UserWarning: Sparsity parameter is too big (0.1) and eliminated all coefficients\n",
      "  warnings.warn(\n",
      "c:\\Users\\Juan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pysindy\\optimizers\\stlsq.py:191: UserWarning: Sparsity parameter is too big (0.1) and eliminated all coefficients\n",
      "  warnings.warn(\n",
      "c:\\Users\\Juan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pysindy\\optimizers\\stlsq.py:191: UserWarning: Sparsity parameter is too big (0.1) and eliminated all coefficients\n",
      "  warnings.warn(\n",
      "c:\\Users\\Juan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pysindy\\optimizers\\stlsq.py:191: UserWarning: Sparsity parameter is too big (0.1) and eliminated all coefficients\n",
      "  warnings.warn(\n",
      "c:\\Users\\Juan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pysindy\\optimizers\\stlsq.py:191: UserWarning: Sparsity parameter is too big (0.1) and eliminated all coefficients\n",
      "  warnings.warn(\n",
      "c:\\Users\\Juan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pysindy\\optimizers\\stlsq.py:191: UserWarning: Sparsity parameter is too big (0.1) and eliminated all coefficients\n",
      "  warnings.warn(\n",
      "c:\\Users\\Juan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pysindy\\optimizers\\stlsq.py:191: UserWarning: Sparsity parameter is too big (0.1) and eliminated all coefficients\n",
      "  warnings.warn(\n",
      "c:\\Users\\Juan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pysindy\\optimizers\\stlsq.py:191: UserWarning: Sparsity parameter is too big (0.1) and eliminated all coefficients\n",
      "  warnings.warn(\n",
      "c:\\Users\\Juan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pysindy\\optimizers\\stlsq.py:191: UserWarning: Sparsity parameter is too big (0.1) and eliminated all coefficients\n",
      "  warnings.warn(\n",
      "c:\\Users\\Juan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pysindy\\optimizers\\stlsq.py:191: UserWarning: Sparsity parameter is too big (0.1) and eliminated all coefficients\n",
      "  warnings.warn(\n",
      "c:\\Users\\Juan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pysindy\\optimizers\\stlsq.py:191: UserWarning: Sparsity parameter is too big (0.1) and eliminated all coefficients\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "experiment_folders = {\n",
    "    \"ethanol\": \"../processing/data/validation/Ethanol_70pc/processed\",\n",
    "}\n",
    "\n",
    "\n",
    "res_exp_dict = {\n",
    "    \"visc\": [],\n",
    "    \"tau\": [],\n",
    "    \"est_visc\": [],\n",
    "    \"est_acc\": [],\n",
    "    \"algorithm\": []\n",
    "}\n",
    "\n",
    "for fluid in experiment_folders:\n",
    "    # Load the values of the circuit elements\n",
    "    with open(experiment_folders[fluid]+\"/microfluidic_setup.yaml\") as cfg_f:\n",
    "        circuit_raw = yaml.safe_load(cfg_f)\n",
    "    circuit, exp_params = {}, {}\n",
    "    for ky, element in circuit_raw[\"elements\"].items():\n",
    "        circuit[ky] = {}\n",
    "        for param in set(element.keys())-set([\"e_sources\", \"e\"]):\n",
    "            if param in element[\"e_sources\"]:\n",
    "                circuit[ky][param] = (element[param] - element[\"e\"][param+\"_e\"],\n",
    "                                      element[param] + element[\"e\"][param+\"_e\"])\n",
    "            else:\n",
    "                circuit[ky][param] = (element[param], element[param])\n",
    "    for ky, element_ranges in circuit.items():\n",
    "        # Extract the random values for the parameters\n",
    "        args = {}\n",
    "        for param, param_ranges in element_ranges.items():\n",
    "            args[param] = np.max([param_ranges[0], param_ranges[1]])\n",
    "        # Resistance\n",
    "        if ky[0] == \"R\":\n",
    "            exp_params[ky.split(\"_\")[0]] = calc_cil_resistance(**args, visc=visc)\n",
    "        # Capacitance\n",
    "        elif ky[0] == \"C\":\n",
    "            exp_params[ky.split(\"_\")[0]] = calc_cil_capacitance(**args)\n",
    "        else: \n",
    "            print(\"Error: element {} not recognized\".format(ky))\n",
    "            exit()\n",
    "\n",
    "    # Load the experimental data (stored in different folders)\n",
    "    X = np.load(experiment_folders[fluid]+\"/X_samples.npy\")\n",
    "    Y = np.load(experiment_folders[fluid]+\"/Y_samples.npy\")\n",
    "    # Also the sampling times!\n",
    "    incT = np.load(experiment_folders[fluid]+\"/incT_samples.npy\")\n",
    "\n",
    "    # Normalize the input data TODO\n",
    "\n",
    "    # Predict\n",
    "    for idx in range(len(X)):\n",
    "        for alg_name in alg_dict.keys():\n",
    "            # Estimate viscosity\n",
    "            R2g = exp_params[\"R2\"] / Y[idx]\n",
    "            tau2 = alg_dict[alg_name]([0.0, incT[idx]], \n",
    "                                      np.transpose(X[idx])[0], \n",
    "                                      np.transpose(X[idx])[1])\n",
    "            est_visc = tau2 / (R2g*exp_params[\"C2\"])\n",
    "\n",
    "            # Save the results\n",
    "            res_exp_dict[\"visc\"].append( visc )\n",
    "            res_exp_dict[\"algorithm\"].append( alg_name )\n",
    "            res_exp_dict[\"est_visc\"].append( est_visc )\n",
    "            res_exp_dict[\"est_acc\"].append( np.abs((Y[idx] - est_visc) / visc) * 100 )\n",
    "            res_exp_dict[\"tau\"].append( tau2 )\n",
    "\n",
    "exp_df = pd.DataFrame.from_dict( res_exp_dict )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Results Analysis\n",
    "### 7.1 Parasite Effect on Algorithm Estimates\n",
    "The calculated stats are the following:\n",
    "- Mean $C_1$ to mean $C_2$ ratio: Percentage that mean $C_1$ suposses to mean $C_2$. This is, how big is (average) parasite capacitance, $C_1$, compared to the main measurement capacitance, $C_2$.\n",
    "- $C_1$ approx. perc. deviation: Percentage that indicates how much $C_1$ varies from its mean value along the Monte Carlo analysis.\n",
    "- Est. viscosity approx. perc. deviation: How much the estimated viscosity varies from its mean value when varying the input values. This indicates how sensible it is to the change in the, in this case, parasite capacitance.\n",
    "- Est. viscosity MAE: Mean Absolute Error of the viscosity estimation with respect to the real value of viscosity.\n",
    "\n",
    "### How to interpret the values?\n",
    "If a high variation of the parasite capacitance, $C_1$, produces a small variation of the estimated viscosity deviation, it means that the sensibility of the calculation is low. This is, the parasite capacitance doesn't affect much to its **precision**. To complete the analysis, it must be observed if it affects to the **accuracy** of the estimation. For example, it could induce an offset that is constant (precision wouldn't be affected), but makes the mean value of the estimate deviate from the real value. This is done by calculating the MAE, which should also remain low for \"big\" parasite capacitances.\n",
    "\n",
    "It can be observed that the effect of the parasite capacitance, $C_1$, alone is low. This is because the problems comes with the time response of the parasite capacitance, and not only the capacitance itself. This means that $R_0$ is also important in this analysis. If this resistance is high, $C_1$ takes more time to fill up, affecting negatively to the estimate of viscosity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real viscosity: 8.80506e-04\n",
      "Mean values:\n",
      "R0                6.688793e+11\n",
      "R1                6.606215e+12\n",
      "C1                8.010100e-15\n",
      "R2                6.606215e+12\n",
      "C2                8.390147e-14\n",
      "sindy_est_visc    8.670246e-04\n",
      "sindy_tau2        5.854584e-01\n",
      "n4sid_est_visc    8.273976e-04\n",
      "n4sid_tau2        5.587003e-01\n",
      "forl_est_visc     1.465035e-03\n",
      "forl_tau2         9.892650e-01\n",
      "lstm_est_visc     8.462474e-04\n",
      "lstm_tau2         5.714286e-01\n",
      "cnn_est_visc      8.533885e-04\n",
      "cnn_tau2          5.762506e-01\n",
      "qlstm_est_visc    8.464243e-04\n",
      "qlstm_tau2        5.715481e-01\n",
      "qcnn_est_visc     8.532594e-04\n",
      "qcnn_tau2         5.761634e-01\n",
      "dtype: float64\n",
      "\n",
      "Standard Deviation values:\n",
      "R0                1.226853e-04\n",
      "R1                0.000000e+00\n",
      "C1                2.269836e-15\n",
      "R2                0.000000e+00\n",
      "C2                1.268536e-29\n",
      "sindy_est_visc    5.617051e-04\n",
      "sindy_tau2        3.792914e-01\n",
      "n4sid_est_visc    8.656409e-07\n",
      "n4sid_tau2        5.845241e-04\n",
      "forl_est_visc     2.347240e-04\n",
      "forl_tau2         1.584974e-01\n",
      "lstm_est_visc     2.181075e-10\n",
      "lstm_tau2         1.472771e-07\n",
      "cnn_est_visc      2.976509e-09\n",
      "cnn_tau2          2.009888e-06\n",
      "qlstm_est_visc    0.000000e+00\n",
      "qlstm_tau2        1.115816e-16\n",
      "qcnn_est_visc     1.070151e-07\n",
      "qcnn_tau2         7.226192e-05\n",
      "dtype: float64\n",
      "\n",
      "Mean C1 to mean C2 ratio: 9.547 %\n",
      "C1 approx. perc. deviation: 28.337 %\n",
      "\n",
      "Algorithm: sindy\n",
      "[Precision] Est. viscosity approx. perc. deviation: 64.785 %\n",
      "[Accuracy]  Est. viscosity MAE: 1.531 %\n",
      "\n",
      "Algorithm: n4sid\n",
      "[Precision] Est. viscosity approx. perc. deviation: 0.105 %\n",
      "[Accuracy]  Est. viscosity MAE: 6.032 %\n",
      "\n",
      "Algorithm: forl\n",
      "[Precision] Est. viscosity approx. perc. deviation: 16.022 %\n",
      "[Accuracy]  Est. viscosity MAE: 66.386 %\n",
      "\n",
      "Algorithm: lstm\n",
      "[Precision] Est. viscosity approx. perc. deviation: 0.000 %\n",
      "[Accuracy]  Est. viscosity MAE: 3.891 %\n",
      "\n",
      "Algorithm: cnn\n",
      "[Precision] Est. viscosity approx. perc. deviation: 0.000 %\n",
      "[Accuracy]  Est. viscosity MAE: 3.080 %\n",
      "\n",
      "Algorithm: qlstm\n",
      "[Precision] Est. viscosity approx. perc. deviation: 0.000 %\n",
      "[Accuracy]  Est. viscosity MAE: 3.871 %\n",
      "\n",
      "Algorithm: qcnn\n",
      "[Precision] Est. viscosity approx. perc. deviation: 0.013 %\n",
      "[Accuracy]  Est. viscosity MAE: 3.094 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Real viscosity: {:.5e}\".format(visc))\n",
    "\n",
    "print(\"Mean values:\")\n",
    "print(res_df.mean())\n",
    "print(\"\\nStandard Deviation values:\")\n",
    "print(res_df.std())\n",
    "\n",
    "# Inputs variations\n",
    "print(\"\\nMean C1 to mean C2 ratio: {:.3f} %\".format(\n",
    "    (1-np.abs((res_df[\"C1\"].mean() - res_df[\"C2\"].mean()) \\\n",
    "           / res_df[\"C2\"].mean())) * 100\n",
    "))\n",
    "print(\"C1 approx. perc. deviation: {:.3f} %\".format(\n",
    "    res_df[\"C1\"].std() / res_df[\"C1\"].mean() * 100\n",
    "))\n",
    "\n",
    "for alg_name in alg_dict.keys():\n",
    "    print(\"\\nAlgorithm: {}\".format(alg_name))\n",
    "    # Standard deviation for est. visc. in percentage\n",
    "    print(\"[Precision] Est. viscosity approx. perc. deviation: {:.3f} %\".format(\n",
    "        res_df[alg_name+\"_est_visc\"].std() / res_df[alg_name+\"_est_visc\"].mean() * 100\n",
    "    ))\n",
    "    # Mean estimation difference to real viscosity\n",
    "    print(\"[Accuracy]  Est. viscosity MAE: {:.3f} %\".format(\n",
    "        np.abs((visc - res_df[alg_name+\"_est_visc\"].mean()) / visc) * 100\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Input Signal Effect on Algorithm Estimates\n",
    "In this section the performance of each algorithm is analyzed with different input signals, with and without noise injected. The objective is to benchmark their accuracy for many different conditions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   algorithm             signal  noise   precision   rel_error   runtime\n",
      "0      sindy    constant_signal   0.00    6.719485  170.738217  0.002594\n",
      "1      sindy    constant_signal   0.04   95.260287   91.481026  0.002456\n",
      "2      sindy  sinusoidal_signal   0.00    0.000375    0.007582  0.002716\n",
      "3      sindy  sinusoidal_signal   0.04   65.534841   39.576290  0.002833\n",
      "4      sindy  triangular_signal   0.00    0.000772    0.080231  0.002935\n",
      "5      sindy  triangular_signal   0.04   18.519227   25.670888  0.001923\n",
      "6      n4sid    constant_signal   0.00    0.046098    0.452462  0.010777\n",
      "7      n4sid    constant_signal   0.04    3.564293   36.662831  0.011218\n",
      "8      n4sid  sinusoidal_signal   0.00    0.118017    0.624883  0.010717\n",
      "9      n4sid  sinusoidal_signal   0.04    4.508431   29.101657  0.009658\n",
      "10     n4sid  triangular_signal   0.00    0.046653    0.687820  0.009952\n",
      "11     n4sid  triangular_signal   0.04    4.543612   30.524661  0.010332\n",
      "12      forl    constant_signal   0.00    1.235046   39.522008  0.001635\n",
      "13      forl    constant_signal   0.04  461.864754  106.091158  0.001816\n",
      "14      forl  sinusoidal_signal   0.00    0.005263    0.380922  0.001102\n",
      "15      forl  sinusoidal_signal   0.04   19.943523   88.528934  0.001535\n",
      "16      forl  triangular_signal   0.00    0.019557    1.615686  0.001972\n",
      "17      forl  triangular_signal   0.04    2.967952   57.951902  0.001815\n",
      "18      lstm    constant_signal   0.00    1.215200    2.380672  0.024165\n",
      "19      lstm    constant_signal   0.04    1.428844    2.325881  0.022836\n",
      "20      lstm  sinusoidal_signal   0.00    1.393198    2.358903  0.023525\n",
      "21      lstm  sinusoidal_signal   0.04    1.350720    2.154507  0.026384\n",
      "22      lstm  triangular_signal   0.00    1.337243    2.399820  0.026480\n",
      "23      lstm  triangular_signal   0.04    1.368539    2.499305  0.026267\n",
      "24       cnn    constant_signal   0.00    1.416621    2.300841  0.006102\n",
      "25       cnn    constant_signal   0.04    1.319616    2.235685  0.007155\n",
      "26       cnn  sinusoidal_signal   0.00    1.447484    2.409937  0.006282\n",
      "27       cnn  sinusoidal_signal   0.04    1.415781    2.184018  0.004548\n",
      "28       cnn  triangular_signal   0.00    1.589451    2.271993  0.007164\n",
      "29       cnn  triangular_signal   0.04    1.619540    2.701786  0.006628\n",
      "30     qlstm    constant_signal   0.00    1.217067    2.377031  0.018763\n",
      "31     qlstm    constant_signal   0.04    1.420038    2.322317  0.018745\n",
      "32     qlstm  sinusoidal_signal   0.00    1.388331    2.338375  0.018131\n",
      "33     qlstm  sinusoidal_signal   0.04    1.349792    2.153397  0.018257\n",
      "34     qlstm  triangular_signal   0.00    1.334659    2.433384  0.020154\n",
      "35     qlstm  triangular_signal   0.04    1.371860    2.496274  0.020262\n",
      "36      qcnn    constant_signal   0.00    1.412213    2.305079  0.000295\n",
      "37      qcnn    constant_signal   0.04    1.320227    2.239532  0.000239\n",
      "38      qcnn  sinusoidal_signal   0.00    1.448071    2.405264  0.000188\n",
      "39      qcnn  sinusoidal_signal   0.04    1.417349    2.184419  0.000425\n",
      "40      qcnn  triangular_signal   0.00    1.608250    2.278663  0.000368\n",
      "41      qcnn  triangular_signal   0.04    1.622629    2.703282  0.000418\n"
     ]
    }
   ],
   "source": [
    "plot_distributions=False\n",
    "\n",
    "# Get the accuracy by algorithm, for each type of input signal, with and without noise\n",
    "analysis_dict = {\n",
    "    \"algorithm\": [],\n",
    "    \"signal\": [],\n",
    "    \"noise\": [],\n",
    "    \"precision\": [],\n",
    "    \"rel_error\": [],\n",
    "    \"runtime\": []\n",
    "}\n",
    "dists = {\n",
    "    \"params\": [],\n",
    "    \"x\": [],\n",
    "    \"y\": []\n",
    "}\n",
    "for alg_name in alg_dict.keys():\n",
    "    for sim_i, sim_cond in enumerate(sim_conditions):\n",
    "        subset_df = res_sig_df.loc[\n",
    "            (res_sig_df[\"algorithm\"] == alg_name) &\n",
    "            (res_sig_df[\"signal\"] == sim_cond[\"sig\"].__name__) & \n",
    "            (res_sig_df[\"noise\"] == sim_cond[\"noise\"])\n",
    "        ]\n",
    "        analysis_dict[\"algorithm\"].append( alg_name )\n",
    "        analysis_dict[\"signal\"].append( sim_cond[\"sig\"].__name__ )\n",
    "        analysis_dict[\"noise\"].append( sim_cond[\"noise\"] )\n",
    "        analysis_dict[\"rel_error\"].append( subset_df[\"est_acc\"].mean() )\n",
    "        analysis_dict[\"precision\"].append( \n",
    "            subset_df[\"est_acc\"].std()\n",
    "         )\n",
    "        analysis_dict[\"runtime\"].append( subset_df[\"time\"].mean() )\n",
    "\n",
    "        if plot_distributions:\n",
    "            # Fit distributions for visualization\n",
    "            # Normal distribution\n",
    "            dists[\"params\"].append( norm_dist.fit( subset_df[\"est_acc\"] ) )\n",
    "            if ( np.max(subset_df[\"est_acc\"]) - np.min(subset_df[\"est_acc\"]) > 0.2):\n",
    "                dists[\"x\"].append( np.linspace(np.min(subset_df[\"est_acc\"]), \n",
    "                                            min(np.max(subset_df[\"est_acc\"]), 250), \n",
    "                                            100) )\n",
    "            else:\n",
    "                dists[\"x\"].append(np.linspace(np.min(subset_df[\"est_acc\"])-0.1, \n",
    "                                            np.max(subset_df[\"est_acc\"])+0.1, \n",
    "                                            100))\n",
    "            dists[\"y\"].append( norm_dist.pdf(dists[\"x\"][-1], *dists[\"params\"][-1]) )\n",
    "            # And plot them\n",
    "            plt.plot(dists[\"x\"][-1], dists[\"y\"][-1])\n",
    "            plt.hist(np.clip(subset_df[\"est_acc\"], a_min=0, a_max=250), \n",
    "                    bins=25, density=True, alpha=0.3, color='b')\n",
    "            plt.title( \"RED. Alg.: \" + alg_name +\n",
    "                    \", Sig.: {}, Noise {}\".format(sim_cond[\"sig\"].__name__, \n",
    "                                                    sim_cond[\"noise\"]) )\n",
    "            plt.grid(True)\n",
    "            plt.figure()\n",
    "\n",
    "benchmark_df = pd.DataFrame(analysis_dict)\n",
    "print(benchmark_df)\n",
    "\n",
    "# Show\n",
    "if plot_distributions: plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 Experimental Validation\n",
    "Lastly, the algorithms were tested with experimental in Section 6, data from different fluids. Here, the statistics are calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  algorithm      precision     rel_error\n",
      "0     sindy            NaN           inf\n",
      "1     n4sid   69629.403000  1.668315e+05\n",
      "2      forl  267781.412603  1.020749e+05\n",
      "3      lstm   15136.239183  4.069525e+04\n",
      "4       cnn    7734.914682  2.370708e+05\n",
      "5     qlstm   10765.470294  3.306753e+04\n",
      "6      qcnn   11363.636053  3.409019e+04\n"
     ]
    }
   ],
   "source": [
    "plot_distributions=False\n",
    "\n",
    "# Get the accuracy by algorithm, for each type of input signal, with and without noise\n",
    "exp_stats_dict = {\n",
    "    \"algorithm\": [],\n",
    "    \"precision\": [],\n",
    "    \"rel_error\": []\n",
    "}\n",
    "\n",
    "for alg_name in alg_dict.keys():\n",
    "    subset_df = exp_df.loc[\n",
    "        (exp_df[\"algorithm\"] == alg_name)\n",
    "    ]\n",
    "    exp_stats_dict[\"algorithm\"].append( alg_name )\n",
    "    exp_stats_dict[\"rel_error\"].append( subset_df[\"est_acc\"].mean() )\n",
    "    exp_stats_dict[\"precision\"].append( \n",
    "        subset_df[\"est_acc\"].std()\n",
    "        )\n",
    "\n",
    "benchmark_df = pd.DataFrame(exp_stats_dict)\n",
    "print(benchmark_df)\n",
    "\n",
    "# Show\n",
    "if plot_distributions: plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
